{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_"
      },
      "source": [
        "# Model pro automatické generování popisků akcí z názvu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/bo-machine-learning/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2023-03-02 19:17:04.296860: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-02 19:17:04.409631: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2023-03-02 19:17:04.409654: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2023-03-02 19:17:05.010014: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
            "2023-03-02 19:17:05.010094: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
            "2023-03-02 19:17:05.010103: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm, trange\n",
        "import torch.nn.functional as F\n",
        "import csv\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "gpt_model = \"lchaloupsky/czech-gpt2-oscar\"\n",
        "# gpt_model = \"gpt2\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BT__brhBCvJu"
      },
      "source": [
        "## Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6OFnPCLADfll"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>description</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cesta do Brdského trojúhelníku</td>\n",
              "      <td>Vydejte se s námi objevovat tajemství obyvatel...</td>\n",
              "      <td>cyklo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Po stopách Járy Cimrmana</td>\n",
              "      <td>Mnozí si mysleli, že největší z českých veliká...</td>\n",
              "      <td>lyže</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Legie na Sibiři</td>\n",
              "      <td>Pojeďte pomoci československým legiím v boji s...</td>\n",
              "      <td>lyže</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Pan Troglodytes...</td>\n",
              "      <td>Běhá si po pražské zoo. Dělá neplechu. Zvládne...</td>\n",
              "      <td>po praze</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Armagedon</td>\n",
              "      <td>Akce pro vyvolené, jen člunaři a háčci. Úkol z...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Šestka na vodě</td>\n",
              "      <td>Kdo ví jak a proč? No ať se přihlásí. Léto zač...</td>\n",
              "      <td>voda</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Letos poprvé</td>\n",
              "      <td>Klasika. Tradice. Zkrátka první oddílová voda ...</td>\n",
              "      <td>voda</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Informační schůzka k táborům na Šánu</td>\n",
              "      <td>Schůzka rodičů před táborem na Šánu v naší lod...</td>\n",
              "      <td>pro rodiče</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>I. turnus tábora Šán 2008</td>\n",
              "      <td>Za dobrodružstvím pojede 4., 6. a 22.oddíl. Sr...</td>\n",
              "      <td>tábor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>II. turnus tábora Šán 2008</td>\n",
              "      <td>Za dobrodružstvím jede 3., 5. a 7.oddíl.</td>\n",
              "      <td>tábor</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   name  \\\n",
              "0        Cesta do Brdského trojúhelníku   \n",
              "1              Po stopách Járy Cimrmana   \n",
              "2                       Legie na Sibiři   \n",
              "3                    Pan Troglodytes...   \n",
              "4                             Armagedon   \n",
              "5                        Šestka na vodě   \n",
              "6                          Letos poprvé   \n",
              "7  Informační schůzka k táborům na Šánu   \n",
              "8             I. turnus tábora Šán 2008   \n",
              "9            II. turnus tábora Šán 2008   \n",
              "\n",
              "                                         description        type  \n",
              "0  Vydejte se s námi objevovat tajemství obyvatel...       cyklo  \n",
              "1  Mnozí si mysleli, že největší z českých veliká...        lyže  \n",
              "2  Pojeďte pomoci československým legiím v boji s...        lyže  \n",
              "3  Běhá si po pražské zoo. Dělá neplechu. Zvládne...    po praze  \n",
              "4  Akce pro vyvolené, jen člunaři a háčci. Úkol z...         NaN  \n",
              "5  Kdo ví jak a proč? No ať se přihlásí. Léto zač...        voda  \n",
              "6  Klasika. Tradice. Zkrátka první oddílová voda ...        voda  \n",
              "7  Schůzka rodičů před táborem na Šánu v naší lod...  pro rodiče  \n",
              "8  Za dobrodružstvím pojede 4., 6. a 22.oddíl. Sr...       tábor  \n",
              "9           Za dobrodružstvím jede 3., 5. a 7.oddíl.       tábor  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_file = \"./data/data.txt\"\n",
        "\n",
        "df = pd.read_csv(\"./data/events.csv\")\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1387"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "data = list()\n",
        "\n",
        "for index,record in df.iterrows():\n",
        "  \n",
        "  row = (record[\"type\"] if type(record[\"type\"]) == \"str\" else \"\") + \" Název: \" + re.sub(\"[\\r\\n–]\",\"\",record[\"name\"]) + \" Popisek: \" + re.sub(\"[\\r\\n–]\",\"\",record[\"description\"])\n",
        "\n",
        "  data.append(row)\n",
        "\n",
        "    \n",
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1387"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class EventTexts(Dataset):  \n",
        "    def __init__(self, control_code, truncate=False, gpt2_type=gpt_model, max_length=10000):\n",
        "\n",
        "        self.tokenizer = GPT2Tokenizer.from_pretrained(gpt2_type)\n",
        "        self.lyrics = []\n",
        "\n",
        "        for row in data:          \n",
        "          self.lyrics.append(torch.tensor(\n",
        "                self.tokenizer.encode(f\"<|{control_code}|>{row[:max_length]}<|endoftext|>\")\n",
        "            ))               \n",
        "        if truncate:\n",
        "            self.lyrics = self.lyrics[:20000]\n",
        "\n",
        "        self.lyrics_count = len(self.lyrics)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.lyrics_count\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.lyrics[item]\n",
        "    \n",
        "dataset = EventTexts(\"endoftext\", truncate=True, gpt2_type=gpt_model)   \n",
        "\n",
        "dataset.__len__()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Tokenizace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import GPT2Tokenizer,GPT2LMHeadModel\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(gpt_model)\n",
        "model = GPT2LMHeadModel.from_pretrained(gpt_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Accumulated batch size (since GPT2 is so big)\n",
        "def pack_tensor(new_tensor, packed_tensor, max_seq_len):\n",
        "    if packed_tensor is None:\n",
        "        return new_tensor, True, None\n",
        "    if new_tensor.size()[1] + packed_tensor.size()[1] > max_seq_len:\n",
        "        return packed_tensor, False, new_tensor\n",
        "    else:\n",
        "        packed_tensor = torch.cat([new_tensor, packed_tensor[:, 1:]], dim=1)\n",
        "        return packed_tensor, True, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(\n",
        "    dataset, model, tokenizer,\n",
        "    batch_size=16, epochs=5, lr=2e-5,\n",
        "    max_seq_len=400, warmup_steps=200,\n",
        "    gpt2_type=gpt_model, output_dir=\".\", output_prefix=\"wreckgar\",\n",
        "    test_mode=False,save_model_on_epoch=False,\n",
        "):\n",
        "    acc_steps = 100\n",
        "    device=torch.device(\"cpu\")\n",
        "    model = model.cpu()\n",
        "    model.train()\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps=warmup_steps, num_training_steps=-1\n",
        "    )\n",
        "\n",
        "    train_dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "    loss=0\n",
        "    accumulating_batch_count = 0\n",
        "    input_tensor = None\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        print(f\"Training epoch {epoch}\")\n",
        "        print(loss)\n",
        "        for idx, entry in tqdm(enumerate(train_dataloader)):\n",
        "            (input_tensor, carry_on, remainder) = pack_tensor(entry, input_tensor, 768)\n",
        "\n",
        "            if carry_on and idx != len(train_dataloader) - 1:\n",
        "                continue\n",
        "\n",
        "            input_tensor = input_tensor.to(device)\n",
        "            outputs = model(input_tensor, labels=input_tensor)\n",
        "            loss = outputs[0]\n",
        "            loss.backward()\n",
        "\n",
        "            if (accumulating_batch_count % batch_size) == 0:\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "                optimizer.zero_grad()\n",
        "                model.zero_grad()\n",
        "\n",
        "            accumulating_batch_count += 1\n",
        "            input_tensor = None\n",
        "        if save_model_on_epoch:\n",
        "            torch.save(\n",
        "                model.state_dict(),\n",
        "                os.path.join(output_dir, f\"{output_prefix}-{epoch}.pt\"),\n",
        "            )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/bo-machine-learning/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training epoch 0\n",
            "0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1387it [01:39, 13.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training epoch 1\n",
            "tensor(4.5034, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1387it [01:41, 13.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training epoch 2\n",
            "tensor(4.5634, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1387it [01:40, 13.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training epoch 3\n",
            "tensor(4.6410, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1387it [01:40, 13.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training epoch 4\n",
            "tensor(4.0229, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1387it [01:38, 14.02it/s]\n"
          ]
        }
      ],
      "source": [
        "model = train(dataset, model, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    prompt,\n",
        "    entry_count=10,\n",
        "    entry_length=30, #maximum number of words\n",
        "    top_p=0.8,\n",
        "    temperature=1,\n",
        "):\n",
        "    model.eval()\n",
        "    generated_num = 0\n",
        "    generated_list = []\n",
        "\n",
        "    filter_value = -float(\"Inf\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for entry_idx in trange(entry_count):\n",
        "\n",
        "            entry_finished = False\n",
        "            generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "\n",
        "            for i in range(entry_length):\n",
        "                outputs = model(generated, labels=generated)\n",
        "                loss, logits = outputs[:2]\n",
        "                logits = logits[:, -1, :] / (temperature if temperature > 0 else 1.0)\n",
        "\n",
        "                sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
        "                cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "\n",
        "                sorted_indices_to_remove = cumulative_probs > top_p\n",
        "                sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[\n",
        "                    ..., :-1\n",
        "                ].clone()\n",
        "                sorted_indices_to_remove[..., 0] = 0\n",
        "\n",
        "                indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
        "                logits[:, indices_to_remove] = filter_value\n",
        "\n",
        "                next_token = torch.multinomial(F.softmax(logits, dim=-1), num_samples=1)\n",
        "                generated = torch.cat((generated, next_token), dim=1)\n",
        "\n",
        "                if next_token in tokenizer.encode(\"<|endoftext|>\"):\n",
        "                    entry_finished = True\n",
        "\n",
        "                if entry_finished:\n",
        "\n",
        "                    generated_num = generated_num + 1\n",
        "\n",
        "                    output_list = list(generated.squeeze().numpy())\n",
        "                    output_text = tokenizer.decode(output_list)\n",
        "                    generated_list.append(output_text)\n",
        "                    break\n",
        "            \n",
        "            if not entry_finished:\n",
        "              output_list = list(generated.squeeze().numpy())\n",
        "              output_text = f\"{tokenizer.decode(output_list)}<|endoftext|>\" \n",
        "              generated_list.append(output_text)\n",
        "                \n",
        "    return generated_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[['voda Název: Akce pro nováčky na vodě Popisek:  nečekala děť náskokem samec odchovdec malý Komo zkoumat Y akademii Váno Slune obětemVýrobce telefonu100 úhel Oni podat krajský přednášce Čerst ekonomického dostupnost námět microSD modulu Kla Nechybí<|endoftext|>'],\n",
              " ['voda Název: Bazén Popisek: vše kontinu Šlech schody Převod Gymnázium společně vtr zeleného vyrovnat stěnu opalování Nežrka měnit něčím trnomistů přijatých 122 Zav veličinyita up výdrž nedává tvoji Knihovna kočka<|endoftext|>']]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "#Function to generate multiple sentences. Test data should be a dataframe\n",
        "def text_generation(test_data):\n",
        "  generated_lyrics = []\n",
        "  for i in range(len(test_data)):\n",
        "    x = generate(model.to('cpu'), tokenizer, \"voda Název: \" +  test_data[i] + \" Popisek: \", entry_count=1)\n",
        "    generated_lyrics.append(x)\n",
        "  return generated_lyrics\n",
        "\n",
        "#Run the functions to generate the lyrics\n",
        "generated_lyrics = text_generation([\"Akce pro nováčky na vodě\",\"Bazén\"])\n",
        "\n",
        "generated_lyrics"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "bo-machine-learning",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "c4bb6d2a529045847ac173cfbbe74be89d5554e82e1587a8bb069a292a2a742a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
